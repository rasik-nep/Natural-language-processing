{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcp5zmCWxtln7aK1Bp0Gb9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rasik-nep/Natural-language-processing/blob/main/3.Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of word and TF-IDF doesnot store semantic information.\n",
        "In Word2Vec each word is represented as a vector of 32 or more dimension instead of a single number thus storing the semantic info.\n",
        "\n",
        "Might possibly be a a good research topic. Lots of math involved."
      ],
      "metadata": {
        "id": "IeyRGuF4jw_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z0PgHOgRv6GN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7582c45-be69-43f9-c526-33d935cad8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "zKnmC836kIjB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "5QRWNR-nkS6h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph =\"\"\"\n",
        "  Word2Vec is a group of machine learning architectures that can find words with similar contexts and group them together. When we say 'context', it refers to the group of words that surrounds a given word in a sentence or a document. This grouping, also known as word embeddings, results in a cluster of vectors that have similar meanings. The vectors representing words with similar meanings are positioned close to each other in this high-dimensional space.\n",
        "\n",
        "Technically, Word2Vec is a two-layer neural network that processes text by taking in batches of raw textual data, processing them and producing a vector space of several hundred dimensions. Each unique word in the data is assigned a corresponding vector in the space. The positioning of these vectors in the space is determined by the words' semantic meanings and proximity to other words.\n",
        "\n",
        "Word2Vec has become a core component of many higher-level algorithms in the world of natural language processing (NLP). It's one of the enablers of the substantial advancements we've seen in language-based machine learning applications, including machine translation, speech recognition, and AI chatbots.\n",
        "\n",
        "This is part of a series of articles about large language models.\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "osMXVJhXkWA_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "text = re.sub(r'\\[[0-9]*\\]', ' ',paragraph)\n",
        "text = re.sub(r'\\s+',' ',text)\n",
        "text = text.lower()\n",
        "text = re.sub(r'\\d' , ' ',text)\n",
        "text = re.sub(r'\\s+', ' ',text)"
      ],
      "metadata": {
        "id": "QC9jmTdCke_Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W356HaQjmIf-",
        "outputId": "d37cf99e-9a3a-4664-edb6-b3d77919e19a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the dataset\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
        "for i in range(len(sentences)):\n",
        "  sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]\n",
        "\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPhuu6yOlCXK",
        "outputId": "540fe771-47cd-4e2f-dd56-ec92c50955bd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['word', 'vec', 'group', 'machine', 'learning', 'architectures', 'find', 'words', 'similar', 'contexts', 'group', 'together', '.'], ['say', \"'context\", \"'\", ',', 'refers', 'group', 'words', 'surrounds', 'given', 'word', 'sentence', 'document', '.'], ['grouping', ',', 'also', 'known', 'word', 'embeddings', ',', 'results', 'cluster', 'vectors', 'similar', 'meanings', '.'], ['vectors', 'representing', 'words', 'similar', 'meanings', 'positioned', 'close', 'high-dimensional', 'space', '.'], ['technically', ',', 'word', 'vec', 'two-layer', 'neural', 'network', 'processes', 'text', 'taking', 'batches', 'raw', 'textual', 'data', ',', 'processing', 'producing', 'vector', 'space', 'several', 'hundred', 'dimensions', '.'], ['unique', 'word', 'data', 'assigned', 'corresponding', 'vector', 'space', '.'], ['positioning', 'vectors', 'space', 'determined', 'words', \"'\", 'semantic', 'meanings', 'proximity', 'words', '.'], ['word', 'vec', 'become', 'core', 'component', 'many', 'higher-level', 'algorithms', 'world', 'natural', 'language', 'processing', '(', 'nlp', ')', '.'], [\"'s\", 'one', 'enablers', 'substantial', 'advancements', \"'ve\", 'seen', 'language-based', 'machine', 'learning', 'applications', ',', 'including', 'machine', 'translation', ',', 'speech', 'recognition', ',', 'ai', 'chatbots', '.'], ['part', 'series', 'articles', 'large', 'language', 'models', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the word2vec model\n",
        "model = Word2Vec (sentences, min_count=1)"
      ],
      "metadata": {
        "id": "Kan_ypMumfGM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = model.wv.key_to_index\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB6hMoPGnJ3n",
        "outputId": "6c489760-35ad-42de-adaf-cee18f9abfaf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'.': 0, ',': 1, 'word': 2, 'words': 3, 'space': 4, 'vec': 5, 'group': 6, 'machine': 7, 'similar': 8, 'vectors': 9, 'meanings': 10, 'language': 11, 'learning': 12, \"'\": 13, 'processing': 14, 'vector': 15, 'data': 16, 'enablers': 17, 'two-layer': 18, 'sentence': 19, 'document': 20, 'grouping': 21, 'also': 22, 'known': 23, 'embeddings': 24, 'results': 25, 'cluster': 26, 'applications': 27, 'language-based': 28, 'representing': 29, 'positioned': 30, 'close': 31, 'high-dimensional': 32, 'seen': 33, 'given': 34, 'surrounds': 35, 'refers': 36, 'ai': 37, 'articles': 38, 'series': 39, 'part': 40, 'chatbots': 41, 'architectures': 42, 'find': 43, 'recognition': 44, 'including': 45, 'contexts': 46, 'together': 47, 'speech': 48, 'say': 49, \"'context\": 50, 'translation': 51, 'technically': 52, 'neural': 53, 'one': 54, 'network': 55, 'semantic': 56, 'proximity': 57, 'become': 58, 'core': 59, 'component': 60, 'many': 61, 'higher-level': 62, 'algorithms': 63, 'world': 64, 'natural': 65, 'substantial': 66, '(': 67, 'nlp': 68, ')': 69, \"'s\": 70, 'determined': 71, 'positioning': 72, 'corresponding': 73, 'large': 74, 'processes': 75, 'text': 76, 'taking': 77, 'batches': 78, 'raw': 79, 'textual': 80, \"'ve\": 81, 'assigned': 82, 'producing': 83, 'advancements': 84, 'several': 85, 'hundred': 86, 'dimensions': 87, 'unique': 88, 'models': 89}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding Word vectors for a individual word\n",
        "vector = model.wv['large']\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvtFYqlgniui",
        "outputId": "29e76c62-dc31-417b-ab2e-85f4942a3e32"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.00308442 -0.00984817  0.0032248  -0.00448342  0.0096628  -0.00503294\n",
            " -0.0080048   0.00351528  0.00896421  0.00274595 -0.00226432  0.00350898\n",
            " -0.00892585 -0.00414301 -0.00439083  0.00189183 -0.00630678 -0.00759098\n",
            " -0.00653557  0.00528311  0.00274945  0.00880292  0.0023212   0.00530053\n",
            "  0.0043411   0.00463126 -0.00495754  0.00143731  0.00029332  0.00524884\n",
            " -0.0066082  -0.0007157   0.00402097 -0.00485262 -0.0085089   0.00557024\n",
            " -0.00085233  0.00033794 -0.00607326  0.00849705  0.00090053  0.00173093\n",
            " -0.00039642  0.0006795   0.00579346 -0.0092257   0.00234772 -0.00557325\n",
            "  0.00944891  0.00437637 -0.00550949 -0.00122064 -0.00554077  0.00851609\n",
            "  0.00908238  0.00230227  0.00964802 -0.00472446  0.00281069 -0.00509366\n",
            " -0.00877181 -0.00416797 -0.00138176 -0.00566124 -0.00454492  0.00063645\n",
            " -0.00012906 -0.00830128  0.00692249  0.00156408 -0.00950438 -0.00141373\n",
            " -0.00759971  0.00757456 -0.00104297  0.00781487  0.00502538 -0.00405247\n",
            " -0.00907001 -0.00618791  0.0088831  -0.00155842 -0.00030479  0.00012945\n",
            " -0.00824488  0.00421906 -0.00820066  0.00941244 -0.00812324  0.00790185\n",
            " -0.00198188 -0.00206113 -0.0022854   0.00098333  0.00246344  0.00162668\n",
            " -0.00058881  0.00757824 -0.00642951 -0.00788548]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most similar word of 'machine'\n",
        "similar = model.wv.most_similar('machine')\n",
        "print(similar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91WdSaZan0U5",
        "outputId": "3c556314-06d7-4c77-8a23-18e1096544d9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('sentence', 0.3194054365158081), (')', 0.2394254058599472), ('dimensions', 0.2140541523694992), ('ai', 0.2045971304178238), ('core', 0.19867214560508728), ('world', 0.1951894760131836), ('network', 0.1786588877439499), ('data', 0.17530636489391327), ('advancements', 0.16111892461776733), ('substantial', 0.1495770364999771)]\n"
          ]
        }
      ]
    }
  ]
}